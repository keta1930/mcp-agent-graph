# 模型与聊天服务

<cite>
**本文档引用的文件**  
- [model_service.py](file://mag/app/services/model_service.py)
- [chat_service.py](file://mag/app/services/chat_service.py)
- [message_builder.py](file://mag/app/services/chat/message_builder.py)
- [prompts.py](file://mag/app/services/chat/prompts.py)
- [conversationService.ts](file://frontend/src/services/conversationService.ts)
- [conversationStore.ts](file://frontend/src/store/conversationStore.ts)
- [file_manager.py](file://mag/app/core/file_manager.py)
- [config.py](file://mag/app/core/config.py)
- [chat_routes.py](file://mag/app/api/chat_routes.py)
</cite>

## 目录
1. [模型服务实现](#模型服务实现)
2. [聊天服务与会话管理](#聊天服务与会话管理)
3. [消息构建与提示词管理](#消息构建与提示词管理)
4. [前端实时对话流处理](#前端实时对话流处理)
5. [核心接口说明](#核心接口说明)
6. [长对话优化策略](#长对话优化策略)

## 模型服务实现

`model_service.py` 负责管理大语言模型（LLM）的配置信息，包括模型名称、API端点、认证密钥及参数设置。该服务通过 `ModelService` 类实现，采用单例模式，确保全局唯一实例。

模型配置信息以 JSON 格式持久化存储在用户主目录下的 `.mag/model.json` 文件中。系统启动时，`FileManager` 会自动加载该文件，若文件不存在则创建默认空配置。配置文件结构为包含多个模型对象的数组，每个对象包含 `name`（模型名称）、`base_url`（API端点）、`model`（后端模型标识）、`api_key`（认证密钥）以及 `temperature`、`max_tokens` 等参数。

`ModelService` 在初始化时调用 `initialize()` 方法，从文件加载配置并为每个模型创建 `AsyncOpenAI` 客户端实例，存储在 `clients` 字典中，键为模型名称。这实现了客户端的预初始化和复用，避免了每次请求时重复创建连接。

对于模型参数的管理，`ModelService` 提供了 `add_model_params()` 和 `prepare_api_params()` 方法。前者将模型配置中的参数（如 `temperature`、`max_tokens`）添加到 API 调用参数中，并进行类型转换；后者则整合基础参数、模型参数和额外参数（如超时、自定义头），为最终的 API 调用做准备。

模型的增删改查（CRUD）操作均通过 `ModelService` 提供的方法实现。添加和更新模型时，会先验证配置的有效性（通过尝试创建客户端），成功后再更新内存中的 `models` 列表和 `clients` 映射，并调用 `FileManager.save_model_config()` 将变更持久化到文件。删除模型则从列表和映射中移除相应条目并保存。

**Section sources**
- [model_service.py](file://mag/app/services/model_service.py#L1-L401)
- [file_manager.py](file://mag/app/core/file_manager.py#L200-L220)
- [config.py](file://mag/app/core/config.py#L50-L55)

## 聊天服务与会话管理

`chat_service.py` 是对话系统的核心，负责处理聊天请求、管理会话上下文和协调模型调用。其核心方法 `chat_completions_stream()` 提供了流式响应接口，支持持久对话和临时对话。

对于持久对话（`conversation_id` 不为空），服务通过 `mongodb_service` 确保对话存在，并使用 `MessageBuilder` 构建包含完整历史消息的上下文。对于临时对话，则仅使用当前消息构建上下文。服务会获取指定模型的配置和客户端，然后调用 `_execute_complete_flow()` 执行完整的对话循环。

该循环支持多轮交互，最大迭代次数为10次。在每一轮中，服务会调用模型生成响应。如果响应包含工具调用（`tool_calls`），服务会使用 `ToolExecutor` 批量执行这些工具，并将工具执行结果作为 `tool` 角色的消息添加回消息列表，然后进行下一轮模型调用，直到没有新的工具调用或达到最大迭代次数。

会话的持久化由 `mongodb_service` 负责。每完成一个完整的对话轮次（从用户输入到模型最终回复），服务会调用 `_save_complete_round()` 将该轮次的所有消息（包括用户、助手和工具消息）保存到数据库，并更新对话的 token 使用统计。对于新对话，还会调用 `_generate_title_and_tags()` 生成对话标题和标签。

**Section sources**
- [chat_service.py](file://mag/app/services/chat_service.py#L1-L447)
- [message_builder.py](file://mag/app/services/chat/message_builder.py#L1-L117)
- [mongodb_service.py](file://mag/app/services/mongodb_service.py)

## 消息构建与提示词管理

`message_builder.py` 中的 `MessageBuilder` 类负责构建符合大模型要求的输入消息序列。它根据对话类型（持久或临时）和系统提示词，将用户输入和历史消息组织成标准的聊天消息列表（`[{"role": "user", "content": "..."}, ...]`）。

`build_chat_messages()` 方法用于持久对话，它会从 `mongodb_service` 获取指定对话的历史消息，并按轮次顺序将所有非系统角色的消息追加到消息列表中，最后添加当前用户消息。`build_temporary_chat_messages()` 则用于临时对话，仅包含系统提示词和当前用户消息。

`prompts.py` 文件集中管理了预定义的提示词模板。这些模板以常量形式存储，如 `SUMMARIZE_TOOL_CONTENT_ZH`（中文内容总结）和 `GENERATE_TITLE_ZH`（中文标题生成）。这些模板定义了模型在执行特定任务（如总结工具结果、生成对话标题）时应遵循的指令和输出格式。

通过 `get_summarize_prompt()` 和 `get_title_prompt()` 函数，可以根据检测到的语言（中文或英文）动态选择相应的提示词模板。例如，在 `chat_service.py` 的 `_summarize_tool_content()` 方法中，会根据内容语言选择总结模板，然后将其与待总结的内容拼接，形成最终的用户提示词，发送给模型进行处理。

**Section sources**
- [message_builder.py](file://mag/app/services/chat/message_builder.py#L1-L117)
- [prompts.py](file://mag/app/services/chat/prompts.py#L1-L81)
- [chat_service.py](file://mag/app/services/chat_service.py#L350-L380)

## 前端实时对话流处理

前端通过 `conversationService.ts` 和 `conversationStore.ts` 与后端建立实时对话流。`conversationService` 提供了 `createChatSSE()` 方法，该方法使用 `fetch` API 向后端 `/chat/completions` 端点发起 POST 请求。

请求头中设置了 `Accept: text/event-stream`，表明期望接收服务器发送事件（SSE）流。请求体包含 `conversation_id`、`user_prompt`、`system_prompt`、`mcp_servers` 和 `model_name` 等参数。`fetch` 返回一个 `ReadableStream`，`createChatSSE()` 方法将其转换为 `ReadableStreamDefaultReader` 并返回。

`conversationStore` 使用 Zustand 状态管理库，维护了当前对话、对话列表、SSE 连接等状态。`startSSEConnection()` 方法接收 `conversationService` 返回的 `reader`，并启动一个异步循环，持续读取流中的数据块。每个数据块被解析为 JSON 格式的 SSE 消息（`SSEMessage`），并通过 `handleSSEMessage()` 进行处理，通常是将新的消息内容更新到 `currentConversation` 状态中，从而驱动 UI 实时更新。

当用户发送新消息时，`conversationStore` 会先调用 `updateCurrentConversationTemporarily()` 将用户消息立即更新到 UI，然后调用 `createChatSSE()` 建立连接，实现“即时反馈”和“流式响应”的用户体验。

**Section sources**
- [conversationService.ts](file://frontend/src/services/conversationService.ts#L1-L255)
- [conversationStore.ts](file://frontend/src/store/conversationStore.ts#L1-L365)
- [chat_routes.py](file://mag/app/api/chat_routes.py#L1-L450)

## 核心接口说明

### create_conversation
此接口在文档中未直接体现，但可通过 `mongodb_service` 的 `ensure_conversation_exists` 方法间接实现。当 `chat_completions_stream` 接收到一个不存在的 `conversation_id` 时，会自动创建一个新对话。

### send_message
对应 `chat_routes.py` 中的 `/chat/completions` POST 接口。请求体 `ChatCompletionRequest` 包含：
- `conversation_id` (可选): 对话ID，为空则为临时对话。
- `user_prompt` (必需): 用户输入的消息。
- `system_prompt` (可选): 系统提示词。
- `mcp_servers` (可选): MCP服务器列表。
- `model_name` (必需): 使用的模型名称。
- `stream` (可选): 是否启用流式响应，默认为 `true`。
- `user_id` (可选): 用户ID。

**调用示例 (Python):**
```python
import requests

url = "http://localhost:8000/chat/completions"
data = {
    "conversation_id": "conv_123",
    "user_prompt": "你好，今天过得怎么样？",
    "model_name": "my_openai_model",
    "stream": True
}

response = requests.post(url, json=data, stream=True)
for line in response.iter_lines():
    if line:
        print(line.decode('utf-8'))
```

### get_model_config
对应 `model_service.py` 中的 `get_all_models()` 方法。该方法返回所有模型的配置列表，但会移除敏感的 `api_key` 字段，仅包含 `name`、`base_url` 和 `model` 等公开信息。前端可通过模型管理界面调用此接口获取可用模型列表。

**Section sources**
- [chat_routes.py](file://mag/app/api/chat_routes.py#L1-L450)
- [model_service.py](file://mag/app/services/model_service.py#L1-L401)

## 长对话优化策略

针对长对话场景，系统实现了两种上下文压缩策略，以应对模型上下文长度限制和性能问题。

**1. 暴力压缩 (Brutal Compact):**
这是一种快速的压缩方式，通过 `compact_conversation` 接口的 `compact_type="brutal"` 参数触发。它会遍历对话的每一轮消息，只保留每轮的系统提示词、用户消息和最后一个助手消息，而丢弃中间的工具调用和工具结果消息。这种方式极大地减少了上下文长度，但会丢失部分中间过程信息。

**2. 精确压缩 (Precise Compact):**
这是一种更智能的压缩方式，通过 `compact_type="precise"` 参数触发。当工具调用返回的内容过长（超过 `compact_threshold`，默认2000字符）时，系统会调用 `_summarize_tool_content()` 方法。该方法使用预定义的总结提示词模板（`SUMMARIZE_TOOL_CONTENT_ZH`/`EN`），调用指定模型对长文本进行总结，然后用总结后的内容替换原始的长内容。这在保留关键信息的同时，显著减少了上下文长度。

这两种策略由 `chat_service.py` 的 `compact_conversation()` 方法统一调度，并通过 `mongodb_service` 执行具体的压缩逻辑。前端可以通过 `conversationService.compactConversation()` 方法触发此操作，有效管理长对话的上下文，优化系统性能和响应速度。

**Section sources**
- [chat_service.py](file://mag/app/services/chat_service.py#L300-L390)
- [chat_routes.py](file://mag/app/api/chat_routes.py#L400-L450)
- [mongodb_service.py](file://mag/app/services/mongodb_service.py)