# 短期记忆（会话上下文）

在每个会话中自动维护的对话上下文。

**记忆类型对比：**

| 类型 | 存储位置 | 范围 | 生命周期 |
|------|---------|------|---------|
| **短期记忆** | 对话轮次 | 单个会话 | 持久保存，直到删除 |
| **长期记忆** | 数据库分类 | 跨会话 | 持久保存，直到删除 |

## 自动管理

系统自动管理短期记忆。您无需手动操作。

## Token 使用

每条消息消耗 token。较长的对话使用更多 token，可能达到模型上下文限制。

**Token 管理：**

| 方面 | 行为 |
|------|------|
| **上下文窗口** | 所有轮次作为上下文发送给模型 |
| **Token 限制** | 由所选模型决定 |
| **长对话** | 可能超过模型的上下文限制 |
| **解决方案** | 使用对话压缩 |

## 对话压缩

当对话变长时，您可以压缩它们以减少 token 使用，同时保留关键信息。

**压缩类型：**

| 类型 | 方法 | 使用场景 |
|------|------|---------|
| **暴力压缩** | 只保留user和assistant每一轮第一条和最后一条消息 | 需要快速减少 |
| **精确压缩** | AI 总结工具内容 | 质量保留重要 |

**如何压缩：**

打开对话设置并选择压缩类型。系统压缩工具输出，同时保持用户和 Agent 消息完整。

**压缩流程：**

```
长工具输出 → 压缩 → 较短摘要 → 减少 token
```

## 对话存储

即使关闭对话，对话也会在数据库中持久保存。您可以稍后返回查看或继续。

## 查看对话

从对话侧边栏访问过去的对话。选择任何对话以查看其完整的消息历史。

**可用操作：**

| 操作 | 说明 |
|------|------|
| **查看** | 阅读所有对话轮次 |
| **继续** | 向对话添加新消息 |
| **导出** | 下载为 JSON 或 Markdown |
| **删除** | 删除对话（软删除） |
| **压缩** | 减少 token 使用 |

## 相关链接

- [用户记忆](long-term/user-memory.zh.md) - 您的持久偏好
- [Agent 记忆](long-term/agent-memory.zh.md) - Agent 的累积知识
- [记忆概览](index.zh.md) - 完整记忆系统
