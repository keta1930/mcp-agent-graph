# 多模态支持

平台现已支持多模态能力，让 Agent 能够处理图像等多种类型的内容。视觉语言模型（VLM）支持已完全实现并可使用。

## 发展阶段

| 阶段 | 支持模态 | 核心能力 | 状态 |
|------|---------|---------|------|
| **第一阶段** | 视觉理解 (VLM) | 图像分析、图文对话 | ✅ 已实现 |
| **后续阶段** | 更多模态 | 持续扩展中 | 规划中 |

## 第一阶段：视觉理解 (VLM)

视觉语言模型支持现已上线，让 Agent 具备"看"和理解图像的能力。

### 已实现的功能

- **图像输入**：在对话中上传图片，Agent 可以看图回答问题
- **图文分析**：理解图片中的文字、物体、场景等信息
- **VLM 模型配置**：在模型管理中添加支持视觉的模型
- **对话历史**：保存包含图片的对话记录

### 使用方法

1. **配置 VLM 模型**：前往模型管理页面，添加支持视觉的模型
2. **上传图片**：在任意对话中，点击图片上传按钮或直接拖拽图片到聊天框
3. **提问**：Agent 将分析图片并回答您关于图片内容的问题
4. **多轮对话**：可以继续追问图片相关的问题，进行深入交流

## 后续规划

视觉理解稳定后，将逐步扩展至图像生成、语音交互、视频处理等更多模态，为 Agent 带来更丰富的感知和创作能力。

---

*视觉能力现已上线！我们将持续关注多模态技术发展，为平台带来更多模态和更丰富的交互能力。*
